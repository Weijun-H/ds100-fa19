{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 12: Using the Bootstrap for Estimation\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** at the top\n",
    "of your solution.\n",
    "\n",
    "## Due Date\n",
    "\n",
    "This assignment is due on **Friday, July 31st, at 11:59PM.**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you will examine the bootstrap in greater detail. The goal is to develop a functional approach to bootstrapping any statistic for any sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as lm\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "# from IPython.display import display, Latex, Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "bootstrap_description",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## The Bootstrap Procedure\n",
    "\n",
    "The bootstrap is a very simple process: \n",
    "* Sample with replacement from the original sample (now the **bootstrap population**). These samples are called **bootstrap samples**. We typically take thousands of bootstrap samples (~10,000 is common).\n",
    "* Calculate the statistic of interest for each bootstrap sample. This statistic is called the **bootstrap statistic**, and the empirical distribution of these bootstrap statistics is an approximation to the **sampling distribution** of the bootstrapped statistic.\n",
    "\n",
    "But why bootstrap instead of just calculating the statistic of interest once on the whole sample? \n",
    "\n",
    "Take sample mean estimator as an example. Suppose $\\{x_i\\}$ are samples coming from an unknown distribution. We can use sample mean $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n x_i$ to estimate the the mean of the population. However, if we obtain another sample set $\\{x_i\\}$, we can get very different results. Therefore, computing the sampling distribution (distribution of the sample mean for all possible sample sets) would be very helpful. From such a distribution, we can obtain the variance of the estimator: $E[E(\\bar{X})-\\bar{X}]^2$.\n",
    "\n",
    "In order to compute the sampling distribution of $\\bar{X}$, we could directly use sampling methods. But that requires us to obtain several different sets of samples $\\{x_i\\}$ directly from the population. If we have $m$ sets of samples and each set contains $n$ subjects (totaling $m \\cdot n$ subjects), we can then use $ \\hat{X} = \\frac{1}{m}\\sum_{j=1}^m \\bar{X_j}$ to approximate $E(\\bar{X})$, and $\\frac{1}{m}\\sum_{j=1}^m (\\hat{X} - \\bar{X_j})^2$ to approximate $E[E(\\bar{X})-\\bar{X}]^2$.\n",
    "\n",
    "However, in reality, this is often unfeasible, and we only have one set of samples (**bootstrap population**). Therefore we can use bootstrap method to resample (sample with replacement) from the **bootstrap population** to obtain $m$ different **bootstrap samples**, where each **bootstrap sample** contains the same amount of data as in the **bootstrap population**. Bootstrap samples should have the same amount of data as the bootstrap population when used to estimate the standard error, perform hypothesis testing, or construct confidence intervals. Otherwise, bootstrap samples just need to have an equal (and reasonable) amount of data.\n",
    "\n",
    "Why do we sample with replacement?\n",
    "Recall that we are trying to mimic the ideal scenario of directly sampling from the original population. In the case where each bootstrap sample has the same amount of data as the bootstrap population, sampling without replacement would cause every bootstrap sample to be identical to the bootstrap population. Even when the bootstrap samples have less data values than the bootstrap population, sampling without replacement would cause the samples to be *based on the original sample*. Instead, sampling with replacement causes our bootstrap samples to be *based on the distribution of the original sample* (which we assume is representative of the original population)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_text1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 1\n",
    "In this lab, let's use the bootstrap method to estimate the distribution of sample mean and sample standard deviation  of our midterm grades. You will be given a noisy sample of grades from this midterm, which is the **bootstrap population**. You should use **sampling with replacement** to resample from this dataset again and again to obtain **bootstrap samples** and compute the **bootstrap statistic**.\n",
    "\n",
    "First, write your own sampling function. The function `simple_resample` samples with replacement from the integers 0 through *n-1* and returns an array of length *n*\n",
    "with the sampled integers. That is, `simple_resample` produces the indices for\n",
    "a single bootstrap replicate from the bootstrap population.\n",
    "\n",
    "Use the `numpy.random.randint` function to do the random sampling. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def simple_resample(n):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n: an integer\n",
    "        \n",
    "    Returns:\n",
    "        an array of length n of a random sample with replacement of\n",
    "        the integers 0, 1, ..., n-1\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "simple_resample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_text1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "### Question 2a\n",
    "\n",
    "Next, let's write the function `bootstrap` which returns an array of length `replicates`, each entry being the `statistic` of interest computed on a bootstrap sample from the `boot_pop` (bootstrap population).\n",
    "\n",
    "In our case, the `statistic` could be the `np.mean` or `np.std` function, and the `resample` could be `simple_resample`. Here we leave them as parameters so that we can switch to other statistic and resample functions later.\n",
    "\n",
    "For each bootstrap sample, you should first use `resample` to obtain samples from the `boot_pop`, then compute the statistic of those samples using the `statistic` method, and put it into your result.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_code1",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def bootstrap(boot_pop, statistic, resample, replicates = 1000):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        boot_pop: an array of shape n x d.\n",
    "        statistic: a function which takes boot_pop and returns a number or array (in the case where we are estimating multiple parameters at once).\n",
    "        resample: a function which takes n and returns a random sample from the integers [0, n)\n",
    "        replicates: the number of resamples\n",
    "        \n",
    "    Returns:\n",
    "        an array of length replicates, each entry being the statistic computed on a bootstrap sample of the data.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_text2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now let's use the bootstrap function to compute the distribution of the sample mean for the midterm grade.\n",
    "\n",
    "First, let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "grades = pd.read_csv(\"grades_sample.csv\")\n",
    "grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_setup2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(grades);\n",
    "plt.plot([np.mean(grades), np.mean(grades)], [0, 0.07], label = 'sample mean')\n",
    "plt.ylim(0, 0.06)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_text3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "Now, use the right parameters to call our `bootstrap` method to obtain the sample mean $\\bar{X}$ for $m$ different bootstrap samples $\\{x_i\\}$. NOTE: Re-running the below cell will give us a different mean and variance each time (Why?).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_code2",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = 1000  # the number of resamples \n",
    "boot_pop = np.array(grades[\"Grade\"])\n",
    "\n",
    "boot_sample_means = ...\n",
    "\n",
    "boot_mean_mean = np.mean(boot_sample_means)\n",
    "boot_var_mean = np.var(boot_sample_means)\n",
    "print('mean of bootstrap mean:', boot_mean_mean, '\\nvariance of bootstrap mean:', boot_var_mean)\n",
    "sns.distplot(boot_sample_means)\n",
    "plt.xlabel(r\"$\\bar{X}$\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_text4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2c\n",
    "\n",
    "Now, use the right parameters to call our `bootstrap` method to obtain the standard deviation $\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} (x_i-\\bar{X})^2}$ for $m$ different bootstrap samples $\\{x_i\\}$. You should use `np.std`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_code3",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "m = 1000\n",
    "boot_pop = np.array(grades[\"Grade\"])\n",
    "\n",
    "boot_sample_std = ...\n",
    "\n",
    "boot_mean_std = np.mean(boot_sample_std)\n",
    "boot_var_std = np.var(boot_sample_std)\n",
    "print('mean of bootstrap std:', boot_mean_std, '\\nvariance of bootstrap std:', boot_var_std)\n",
    "sns.distplot(boot_sample_std)\n",
    "plt.xlabel(r\"$STD(X)$\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_true",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The true mean for the midterm grade is 80.1, and the standard deviation is 9.20.\n",
    "Compare your results with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_text1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 3\n",
    "Now let's use the bootstrap method to analyze more sophisticated estimators – the coefficients of linear models.\n",
    "\n",
    "Let's use the `mpg` dataset from seaborn, that we looked at in an earlier lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = sns.load_dataset('mpg')\n",
    "mpg = mpg.dropna()\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at the relationship between `horsepower` and `mpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(mpg['horsepower'], mpg['mpg']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be clear that a line of best fit going through these points would not pass through the origin, but for the sake of simplicity, let's start by building a simple linear model **without an intercept term** to model `mpg` as a function of `horsepower`. We will assume there is some true slope $\\theta^*$ that we are trying to estimate, such that\n",
    "\n",
    "$$\\text{mpg} = \\theta^* \\cdot \\text{horsepower}$$\n",
    "\n",
    "Our prediction for `mpg` is then\n",
    "\n",
    "$$\\hat{\\text{mpg}} = \\theta \\cdot \\text{horsepower}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_text2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In Homework 5, you showed that the value of $\\hat{\\theta}$ that minimized average squared loss for this model was \n",
    "\n",
    "$${\\hat{\\theta}} = \\frac{\\sum x_iy_i}{\\sum x_i^2}$$\n",
    "\n",
    "We say that the above $\\hat{\\theta}$ is the **least squares estimator** for $\\theta^*$.\n",
    "\n",
    "### Question 3a\n",
    "\n",
    "Below, implement the function `single_parameter_estimator`, which takes in a dataset `d` and returns the least squares estimate for $\\theta^*$ defined above.\n",
    "\n",
    "Note that in order to perform the bootstrap, we need to combine `x`, `y` into a $n \\times 2$ array `d`. So `d[:,0]` is equivalent to `x`, and `d[:,1]` is equivalent to `y`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_code1",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def single_parameter_estimator(d):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        d: A n*2 array which contains x and y. d[:,0] would be x, d[:,1] would be y.\n",
    "        \n",
    "    Returns:\n",
    "        The optimal theta that minimizes average squared loss for this dataset and model\n",
    "        .\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "data_3a = mpg[['horsepower', 'mpg']].values\n",
    "single_parameter_estimator(data_3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_text3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now, we can use our previous `bootstrap` function to obtain different estimated $\\theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_code2",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "replicates = 1000\n",
    "\n",
    "boot_theta = bootstrap(data_3a, single_parameter_estimator, simple_resample, replicates)\n",
    "\n",
    "boot_theta_mean = np.mean(boot_theta)\n",
    "boot_theta_var = np.var(boot_theta)\n",
    "print('mean of bootstrap theta:', boot_theta_mean, '\\nvariance of bootstrap theta:', boot_theta_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_text4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Finally, let's plot the distribution of `boot_theta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_plot",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(boot_theta);\n",
    "plt.xlabel(r\"$\\theta*$\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3b\n",
    "\n",
    "As we saw in lecture, we can extend this procedure to a linear model with any number of coefficients. Let's now suppose we are trying to model `mpg` as a linear function of `horsepower`, `weight`, and `acceleration`, that contains an intercept term. We are looking to estimate $\\theta_0^*, \\theta_1^*, \\theta_2^*,$ and $\\theta_3^*$ in\n",
    "\n",
    "$$\\text{mpg} = \\theta_0^* + \\theta_1^* \\cdot \\text{horsepower} + \\theta_2^* \\cdot \\text{weight} + \\theta_3^* \\cdot \\text{acceleration} + \\epsilon$$\n",
    "\n",
    "Note that this model makes predictions as $\\text{predicted mpg} = \\hat{\\theta_0} + \\hat{\\theta_1} \\cdot \\text{horsepower} + \\hat{\\theta_2} \\cdot \\text{weight} + \\hat{\\theta_3} \\cdot \\text{acceleration}$; this is really nothing new.\n",
    "\n",
    "\n",
    "If we want to bootstrap the sampling distribution of the estimators of multiple coefficients, it's probably best to use `scikit-learn`'s `LinearRegression` package to determine what the least squares estimates of our parameters are. Here's how we _could have_ written the `single_parameter_estimator` function above, using `scikit-learn` instead of hard-coding the optimal $\\hat{\\theta}$:\n",
    "\n",
    "```py\n",
    "def single_parameter_estimator_sk(d):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        d: A n*2 array which contains x and y. d[:,0] would be x, d[:,1] would be y.\n",
    "        \n",
    "    Returns:\n",
    "        The optimal theta that minimizes average squared loss for this dataset and model\n",
    "        .\n",
    "    \"\"\"\n",
    "    model = lm.LinearRegression(fit_intercept = False)\n",
    "    model.fit(d[:, 0].reshape(-1, 1), d[:, 1])\n",
    "    return model.coef_[0]\n",
    "```\n",
    "\n",
    "Below, fill in the code for `four_parameter_estimator(d)`, that takes in a dataset `d` that has the same number of rows as the `mpg` dataset, and 4 columns (one each for `horsepower`, `acceleration`, `weight`, and `mpg`). It should return an **array** with 4 elements – the least squares estimates for all four model parameters (i.e. the model parameters that minimize average squared loss for this dataset).\n",
    "\n",
    "To be explicit, the parameters we're solving for are the intercept term and the slopes on `horsepower`, `acceleration`, and `weight`. \n",
    "\n",
    "HINT: Try using `model.intercept_` and `model.coef_`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_parameter_estimator(d):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        d: A n*4 array which contains X and y. \n",
    "        d[:, :3] contains our design matrix X, \n",
    "        d[:, 3] contains our true response values y.\n",
    "\n",
    "    Returns:\n",
    "        The optimal theta that minimizes average squared loss for this dataset and model\n",
    "        .\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "data_3b = mpg[['horsepower', 'weight', 'acceleration', 'mpg']].values\n",
    "four_parameter_estimator(data_3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to use our `bootstrap` method to compute the estimated sampling distribution for all four of our parameters. Observe what happens when we call `bootstrap(data_3b, four_parameter_estimator, simple_resample, replicates)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_multiple = bootstrap(data_3b, four_parameter_estimator, simple_resample, replicates)\n",
    "bootstrap_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_multiple.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous questions, the result of calling `bootstrap` was an array of length `replicates`. However, now it is a matrix of size `(replicates, 4)` since for each bootstrap resample, we are estimating four parameters, not one.\n",
    "\n",
    "In `bootstrap_multiple`, column `i` contains the estimated values of $\\theta_i^*$.\n",
    "\n",
    "Below, we display a plot with the bootstrapped sampling distributions of all four parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2,2,figsize=(10, 8))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.title(r'Bootstrapped Sampling Distribution for $\\theta_{}^*$'.format(i))\n",
    "    sns.distplot(bootstrap_multiple[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3c\n",
    "\n",
    "Recall, we can use bootstrapped parameter estimates to create confidence intervals for the true model parameters.\n",
    "\n",
    "Let's focus on the bootstrapped estimates for $\\theta_3^*$, since they happen to be the most interesting. Below, set `left_endpt` and `right_endpt` to be the left and right endpoints for a **95% confidence interval** for the value of $\\theta_3^*$.\n",
    "- Hint: You will need to use `np.percentile`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_endpt = ...\n",
    "right_endpt = ...\n",
    "\n",
    "left_endpt, right_endpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we plot your confidence interval along with the distribution of bootstrapped estimates for $\\theta_3^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(bootstrap_multiple[:, 3]);\n",
    "plt.plot([left_endpt, right_endpt], [0, 0], linewidth = 10, label = '95% CI');\n",
    "plt.legend();\n",
    "plt.xlabel(r\"$\\theta_3*$\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did Question 3c correctly, you should notice that 0 is in the confidence interval for $\\theta_3^*$. Since this is the case, we would say we don't have enough evidence to reject the claim that the true slope is 0, i.e. that `weight` does not help explain `mpg` in a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "That seems to be a little strange. Intuitively, we'd think the weight of a car impacts its fuel economy. So why is it that the slope for weight in the previous question was found to be not significantly different than 0? Let's explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's look at a scatter plot between `weight` and `mpg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data = mpg,\n",
    "           x = 'weight', \n",
    "           y = 'mpg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that they are quite strongly negatively correlated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg[['weight', 'mpg']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means, at the very least, that `weight` should provide some explanatory power when predicting `mpg`. So why was 0 in the confidence interval for the true slope on `weight` in the previous question?\n",
    "\n",
    "Let's dig a little deeper. Let's look at the correlation between `horsepower`, `acceleration`, and `weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg[['horsepower', 'acceleration', 'weight']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4a\n",
    "\n",
    "What do you notice above? What does this have to do with 0 being in the 95% confidence interval for $\\theta_3^*$ above?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4b\n",
    "\n",
    "Let's now create a `two_parameter_estimator` that returns the estimates for the intercept and slope for the following model:\n",
    "\n",
    "$$\\text{mpg} = \\theta_0^* + \\theta_1^* \\cdot \\text{weight} + \\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is already filled in for you\n",
    "def two_parameter_estimator(d):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        d: A n*2 array which contains X and y. \n",
    "        d[:, 0] contains our x,\n",
    "        d[:, 1] contains our true y.\n",
    "\n",
    "    Returns:\n",
    "        The optimal theta that minimizes average squared loss for this dataset and model.\n",
    "    \"\"\"\n",
    "    model = lm.LinearRegression(fit_intercept = True)\n",
    "    model.fit(d[:, 0].reshape(-1, 1), d[:, 1])\n",
    "    return np.append(model.intercept_, model.coef_)\n",
    "\n",
    "data_4 = mpg[['weight', 'mpg']].values\n",
    "two_parameter_estimator(data_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the following cell, set `bootstrap_4` to a `n x 2` array that contains the results of calling our `bootstrap` method on the above estimator and data.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_4 = ...\n",
    "bootstrap_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4c\n",
    "\n",
    "Lastly, we look at the bootstrapped sampling distribution for the estimate of the slope on `weight` in the above simple linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 5))\n",
    "sns.distplot(bootstrap_4[:, 1]);\n",
    "plt.xlabel(r\"$\\theta_1*$\");\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 is not in this confidence interval. However, the estimates for the slope on `weight` are all very small. \n",
    "\n",
    "Why are they all so small? Does this mean the linear association between `weight` and `mpg` is not statistically significant? Answer below.\n",
    "\n",
    "- Hint: Look closely at the scatter plot at the start of Question 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before     running the cell below, so that all images/graphs appear in the output. The cell below will generate     a zipfile for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
